{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import sys\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import logit\n",
    "\n",
    "from sepsis_utils import sepsis_utils as su\n",
    "from sepsis_utils import roc_utils as ru\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# used for train/test splits\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# used to impute mean for data\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# normalize the data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# logistic regression is our model of choice\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# used to create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# used to calculate AUROC/accuracy\n",
    "from sklearn import metrics\n",
    "\n",
    "# for calibration curve of severity scores\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# default colours for prettier plots\n",
    "col = [[0.9047, 0.1918, 0.1988],\n",
    "    [0.2941, 0.5447, 0.7494],\n",
    "    [0.3718, 0.7176, 0.3612],\n",
    "    [1.0000, 0.5482, 0.1000],\n",
    "    [0.4550, 0.4946, 0.4722],\n",
    "    [0.6859, 0.4035, 0.2412],\n",
    "    [0.9718, 0.5553, 0.7741],\n",
    "    [0.5313, 0.3359, 0.6523]];\n",
    "marker = ['v','o','d','^','s','o','+']\n",
    "ls = ['-','-','-','-','-','s','--','--']\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df = su.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the columns in our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have: ICU intime/outtime, suspected infection time, whether the microbiology culture was positive, some demographics, comorbidities, outcomes, and the severity scores. \n",
    "\n",
    "The severity scores appear twice. With no suffix, the score is extracted at a [0, 24] hour window centered around ICU admission - except labs have an extended [-6, 24] hour window (i.e. 'sofa' is extracted in this way).\n",
    "\n",
    "The second set of scores, with suffix 'si' (suspected infection), are extracted in a [-48, 24] hour window around the suspected_infection_time (i.e. 'sofa_si' is extracted in this window)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time of suspected infection\n",
    "\n",
    "Suspected infection is defined as:\n",
    "\n",
    "* Antibiotics within 72 hours of a culture\n",
    "* A culture within 24 hours of antibiotics\n",
    "\n",
    "We can extract antibiotic usage from the, PRESCRIPTIONS, INPUTEVENTS_MV and INPUTEVENTS_CV tables. We can extract time of blood cultures from the MICROBIOLOGYEVENTS table. Detail is given in defining-suspected-infection.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# distribution of time of infection\n",
    "xi = np.linspace(-72, 72, 72*2+1)\n",
    "\n",
    "idxKeep = ~df.suspected_infection_time.isnull()\n",
    "tmp = (df.loc[idxKeep,'suspected_infection_time'] - df.loc[idxKeep,'intime']).values / np.timedelta64(1, 'h')\n",
    "\n",
    "N_firstday = sum( (tmp>-24) & (tmp<24) )\n",
    "plt.figure(figsize=[6,6])\n",
    "plt.hist( tmp, bins=xi )\n",
    "plt.title('{} patients suspected between [-24,24] ({:2.2f}%).'.format(\n",
    "        N_firstday, N_firstday*100.0 / tmp.shape[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most patients are suspected of infection either before, or at the time of their ICU admission. This motivates the decision to evaluate the performance of the scores at ICU admission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cohort\n",
    "\n",
    "The below code creates our cohort of interest. This cohort is used to apply inclusion criteria by means of an inner join. Inclusion criteria are:\n",
    "\n",
    "* Adult patient, i.e. age >= 16\n",
    "* First ICU stay for the patient\n",
    "* Suspected of infection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('{:5g} - total number of ICU stays in MIMIC.'.format(df.shape[0]))\n",
    "\n",
    "idx = df.age > 1\n",
    "N_rem = df.shape[0] - np.sum(idx)\n",
    "print('{:5g}   include only adult ICU stays (removed {}).'.format(\n",
    "        np.sum(idx), N_rem))\n",
    "\n",
    "N_rem = np.sum(idx) - np.sum(idx & (df['icustay_num'] == 1))\n",
    "idx = idx & (df['icustay_num'] == 1)\n",
    "print('{:5g}   ... on their first ICU stay  (removed {}).'.format(\n",
    "        np.sum(idx), N_rem))\n",
    "\n",
    "\n",
    "N_rem = np.sum(idx) - np.sum(idx & (~df['suspected_infection_time'].isnull()))\n",
    "idx = idx & (~df['suspected_infection_time'].isnull())\n",
    "print('{:5g}   ... suspected of infection   (removed {}).'.format(\n",
    "        np.sum(idx), N_rem))\n",
    "\n",
    "\n",
    "idxRem = (df['suspected_infection_time']-df['intime'])<np.timedelta64(1,'D')\n",
    "N_rem = np.sum(idx) - np.sum(idx & idxRem)\n",
    "idx = idx & idxRem\n",
    "print('{:5g}   ... suspected before 1st day (removed {}).'.format(\n",
    "        np.sum(idx), N_rem))\n",
    "\n",
    "df = df.loc[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "su.print_demographics(df)\n",
    "\n",
    "print('')\n",
    "print('{:5g} have qSOFA >= 2 ({:2.2f}%).'.format(\n",
    "    (df.qsofa.values >= 2).sum(),100.0*(df.qsofa.values >= 2).mean()))\n",
    "\n",
    "print('{:5g} have SOFA >= 2 ({:2.2f}%).'.format(\n",
    "    (df.sofa.values >= 2).sum(),100.0*(df.sofa.values >= 2).mean()))\n",
    "\n",
    "print('{:5g} have Sepsis-3 ({:2.2f}%).'.format(\n",
    "    (df.sepsis3).sum(),100.0*(df.sepsis3).mean()))\n",
    "\n",
    "print('{:5g} have SIRS >= 2 ({:2.2f}%).'.format(\n",
    "    (df.sirs.values >= 2).sum(),100.0*(df.sirs.values >= 2).mean()))\n",
    "\n",
    "print('{:5g} have LODS >= 2 ({:2.2f}%).'.format(\n",
    "    (df.lods.values >= 2).sum(),100.0*(df.lods.values >= 2).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model + scores\n",
    "\n",
    "The original paper evaluates a *baseline model* with the addition of the various severity scores. \n",
    "\n",
    "> To measure predictive validity, a baseline risk model was created for in-hospital mortality based on preinfection criteria using multivariable logistic regression. The baseline model included age (as a fractional polynomial), sex, race/ethnicity (black, white, or other), and the weighted Charlson comorbidity score (as fractional polynomial) as a measure of chronic comorbidities.\n",
    "\n",
    "This baseline model includes:\n",
    "\n",
    "* age (fractional polynomial)\n",
    "* sex\n",
    "* ethnicity\n",
    "* Charlson comorbidities (fractional polynomial)\n",
    "\n",
    "We will reproduce this model, with the following caveats:\n",
    "\n",
    "1. We will build and evaluate the model on the same dataset, so our estimates are \"apparent\"\n",
    "2. We will use Elixhauser comorbidities, not Charlson comorbidities\n",
    "3. We may not have identical fractional polynomial terms (as we are rebuilding the model on our dataset)\n",
    "\n",
    "The following code block extracts the covariates for the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_header = ['age','elixhauser_hospital','hospital_expire_flag','angus',\n",
    "            'is_male','race_black','race_other',\n",
    "            'qsofa','sofa','sepsis3','sirs','lods']\n",
    "\n",
    "X = df[X_header].values\n",
    "\n",
    "# we'll write out the design matrix for the MFP model here - this is used by the R code\n",
    "np.savetxt('sepsis3-design-matrix.csv', X, fmt='%4.4f',\n",
    "           delimiter=',', header=','.join(X_header), comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the data to file\n",
    "\n",
    "The dataframes will be loaded directly from a file, rather than the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('sepsis3-df.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `X` data which was written to 'sepsis3-design-matrix.csv' will be used by the `print_auc_table_baseline` function to evaluate the AUROC of the scores when incorporated with the baseline model.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Table of AUROCs of scores on their own, with p-values.')\n",
    "# define outcome\n",
    "target_header = \"hospital_expire_flag\"\n",
    "y = df[target_header].values == 1\n",
    "\n",
    "# define the covariates to be added in the MFP model (used for table of AUROCs)\n",
    "preds_header = ['sirs','sofa','lods','qsofa']\n",
    "\n",
    "su.print_auc_table(df, preds_header, target_header)\n",
    "\n",
    "\n",
    "# model development - baseline covariates\n",
    "mdl_formula = target_header + \" ~ age + elixhauser_hospital + race_black + race_other + is_male\"\n",
    "print('\\nBaseline model development...')\n",
    "model = logit(formula=mdl_formula, data=df).fit()\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "print('\\nAUROC of the baseline, and models built using baseline covariates + score listed..')\n",
    "\n",
    "for score_added in ['Baseline','sirs','qsofa','sofa','lods']:\n",
    "    frm = mdl_formula\n",
    "    if score_added != 'Baseline':\n",
    "        frm = frm + ' + ' + score_added\n",
    "        \n",
    "    model = logit(formula=frm, data=df).fit(disp=0)\n",
    "    auc_mdl = metrics.roc_auc_score(df[target_header],model.predict())\n",
    "    print('{:10s} {:0.3f}'.format(score_added, auc_mdl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
