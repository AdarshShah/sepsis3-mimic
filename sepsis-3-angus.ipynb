{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sepsis-3 evaluation in the MIMIC-III database\n",
    "\n",
    "This notebook goes over the evaluation of the new Sepsis-3 guidelines in the MIMIC database. The goals of this analysis include:\n",
    "\n",
    "1. Evaluating the Sepsis-3 guidelines in MIMIC using the same methodology as in the research paper\n",
    "2. Evaluating the Sepsis-3 guidelines against ANGUS criteria\n",
    "3. Assessing if there are interesting subgroup(s) which are missed by the criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sepsis_utils import sepsis_utils as su\n",
    "from sepsis_utils import roc_utils as ru\n",
    "\n",
    "# used to calculate AUROC\n",
    "from sklearn import metrics\n",
    "\n",
    "# default colours for prettier plots\n",
    "col = [[0.9047, 0.1918, 0.1988],\n",
    "    [0.2941, 0.5447, 0.7494],\n",
    "    [0.3718, 0.7176, 0.3612],\n",
    "    [1.0000, 0.5482, 0.1000],\n",
    "    [0.4550, 0.4946, 0.4722],\n",
    "    [0.6859, 0.4035, 0.2412],\n",
    "    [0.9718, 0.5553, 0.7741],\n",
    "    [0.5313, 0.3359, 0.6523]];\n",
    "marker = ['v','o','d','^','s','o','+']\n",
    "ls = ['-','-','-','-','-','s','--','--']\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('sepsis3-df.csv',sep=',')\n",
    "df_mdl = pd.read_csv('sepsis3-design-matrix.csv',sep=',')\n",
    "\n",
    "# define outcome\n",
    "target_header = \"angus\"\n",
    "y = df[target_header].values == 1\n",
    "\n",
    "# define the covariates to be added in the MFP model (used for table of AUROCs)\n",
    "preds_header = ['sirs','qsofa','sofa','mlods']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study questions\n",
    "\n",
    "1. How well do the guidelines detect sepsis (Angus criteria) in the antibiotics/culture subset?\n",
    "2. How well do the guidelines predict mortality (in-hospital) in the antibiotics/culture subset?\n",
    "3. What factors would improve the sensitivity of the guidelines?\n",
    "4. What factors would improve the specificity of the guidelines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angus criteria evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SEPSIS-3 guidelines for Angus criteria sepsis \n",
      "\n",
      "Accuracy = 0.595192449491\n",
      "\n",
      "Confusion matrix\n",
      "      \tang=0 \tang=1 \n",
      "sep3=0\t  2061\t  1273\tNPV=61.82\n",
      "sep3=1\t  1472\t  1975\tPPV=57.30\n",
      "   \t58.34\t60.81\tAcc=59.52\n",
      "   \tSpec\tSens\n"
     ]
    }
   ],
   "source": [
    "yhat = df.sepsis3.values\n",
    "print('\\n SEPSIS-3 guidelines for Angus criteria sepsis \\n')\n",
    "print('Accuracy = {}'.format(metrics.accuracy_score(y, yhat)))\n",
    "su.print_cm(y, yhat, header1='ang',header2='sep3') # print confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions using various levels of confounder adjustment are calculated in the subfunctions `calc_predictions`:\n",
    "\n",
    "* `model=None` - the severity scores on their own\n",
    "* `model='baseline'` - the severity scores in a vanilla regression\n",
    "* `model='mfp'` -the severity scores in a fractional polynomial regression (calls an R script)\n",
    "\n",
    "For Angus criteria we do not adjust for other factors when presenting the AUROCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = su.calc_predictions(df, preds_header, target_header, model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \tsirs                \tqsofa               \tsofa                \tmlods               \t\n",
      "sirs \t0.607 [0.594, 0.620]\t0.436 [0.413, 0.457]\t0.179 [0.162, 0.196]\t0.231 [0.210, 0.251]\t\n",
      "qsofa\t0.351               \t0.600 [0.587, 0.612]\t0.271 [0.260, 0.281]\t0.356 [0.343, 0.369]\t\n",
      "sofa \t< 0.001               \t< 0.001               \t0.682 [0.669, 0.694]\t0.873 [0.868, 0.878]\t\n",
      "mlods\t< 0.001               \t< 0.001               \t0.429               \t0.685 [0.673, 0.698]\t\n"
     ]
    }
   ],
   "source": [
    "# reproduce the AUC table\n",
    "su.print_auc_table(preds, y, preds_header)\n",
    "su.print_auc_table_to_file(preds, y, preds_header=preds_header,\n",
    "                           filename='auc-table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operating point statistics\n",
    "\n",
    "This section evaluates the standard operating point statistics:\n",
    "\n",
    "* sensitivity (% of true positives which are correctly classified)\n",
    "* specificity (% of true negatives which are correctly classified)\n",
    "* positive predictive value (given a positive prediction is made, what % are correct)\n",
    "* negative predictive value (given a negative prediction is made, what % are correct)\n",
    "* F1 score (harmonic mean of sensitivity and PPV)\n",
    "\n",
    "In addition, we evaluate the number of false positives per 100 cases, or NFP/100. We feel this gives helpful perspective in interpretting the positive predictive value of the prediction and its relationship to the prevalance of the outcome. In this context, the measure can be summarized as: given 100 patients with suspected infection, how many will each algorithm inappropriately give a positive prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric\n",
      "\n",
      "\n",
      "     \tseps3               \tqSOFA               \tSOFA                \tSIRS                \tmLODS               \n",
      "TN   \t 2061           \t 1878           \t  792           \t  992           \t 1633           \n",
      "FP   \t 1472           \t 1655           \t 2741           \t 2541           \t 1900           \n",
      "FN   \t 1273           \t 1173           \t  264           \t  530           \t  670           \n",
      "TP   \t 1975           \t 2075           \t 2984           \t 2718           \t 2578           \n",
      "Sens \t60.81 [0.59, 0.62]\t63.89 [0.62, 0.66]\t91.87 [0.91, 0.93]\t83.68 [0.82, 0.85]\t79.37 [0.78, 0.81]\n",
      "Spec \t58.34 [0.57, 0.60]\t53.16 [0.51, 0.55]\t22.42 [0.21, 0.24]\t28.08 [0.27, 0.30]\t46.22 [0.45, 0.48]\n",
      "PPV  \t57.30 [0.56, 0.59]\t55.63 [0.54, 0.57]\t52.12 [0.51, 0.53]\t51.68 [0.50, 0.53]\t57.57 [0.56, 0.59]\n",
      "NPV  \t61.82 [0.60, 0.63]\t61.55 [0.60, 0.63]\t75.00 [0.72, 0.78]\t65.18 [0.63, 0.68]\t70.91 [0.69, 0.73]\n",
      "F1   \t59.00             \t59.47             \t66.51             \t63.90             \t66.74             \n",
      "NTP  \t29.13             \t30.60             \t44.01             \t40.08             \t38.02             \n",
      "NFP  \t21.71             \t24.41             \t40.42             \t37.47             \t28.02             \n"
     ]
    }
   ],
   "source": [
    "# sepsis3 defined as qSOFA >= 2 and SOFA >= 2\n",
    "yhat_all = [df.sepsis3.values,\n",
    "            df.qsofa.values >= 2,\n",
    "            df.sofa.values >= 2,\n",
    "            df.sirs.values >= 2,\n",
    "            df.mlods.values >= 2]\n",
    "yhat_names = ['seps3', 'qSOFA', 'SOFA', 'SIRS', 'mLODS']\n",
    "\n",
    "# define \"targets\", angus critera\n",
    "y_all = [y for x in yhat_names]\n",
    "\n",
    "stats_all = su.get_op_stats(yhat_all, y_all,\n",
    "               yhat_names=yhat_names,\n",
    "               header=target_header)\n",
    "\n",
    "su.print_op_stats(stats_all,\n",
    "               yhat_names=yhat_names,\n",
    "               header=target_header)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
